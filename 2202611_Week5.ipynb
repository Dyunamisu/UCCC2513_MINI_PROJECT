{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7569d7b3-e43a-47c2-a6b5-68b228bddf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "if not cv.useOptimized():\n",
    "    cv.setUseOptimized(True)\n",
    "\n",
    "cv.useOptimized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2815c5-2fea-4b68-ad30-2984448553be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import display_image, display_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30cb148-62ca-46af-970d-ddaeef38bc9b",
   "metadata": {},
   "source": [
    "# Weekly activity\n",
    "###### 1)Rotate image by 45 degrees without cropping the sides of the image. (Hint: There are 2 strategies to tackle these problems). Use \"lena.jfif\" as the input image.\n",
    "- Use external libraries imutils.\n",
    "- Modify the transformation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae95a7cd-628b-4284-b797-a7f25561eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first method\n",
    "import imutils\n",
    "img = cv.imread('images/lena.jfif')\n",
    "rotated_img = imutils.rotate_bound(img,45)\n",
    "display_image(\"rotate 45\",rotated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f22687ff-0fc8-4906-b352-c9ce9b41b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second method\n",
    "img = cv.imread('images/lena.jfif')\n",
    "center = (w // 2, h // 2)\n",
    "M = cv.getRotationMatrix2D(center, -45, 1)\n",
    "cos = np.abs(M[0, 0])\n",
    "sin = np.abs(M[0, 1])\n",
    "new_w = int((h * sin) + (w * cos))\n",
    "new_h = int((h * cos) + (w * sin))\n",
    "M[0, 2] += (new_w / 2) - center[0]\n",
    "M[1, 2] += (new_h / 2) - center[1]\n",
    "rotated_img = cv.warpAffine(img, M, (new_w, new_h))\n",
    "display_image(\"Rotated Image (45 degrees)\", rotated_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c6863-87b3-46bc-8509-e6d95a785002",
   "metadata": {},
   "source": [
    "##### 2)Use the images with titles: \"flower.jfif\" and \"native-bee.png\". I want to put flower above an image. If I add two images, it will change color. If I blend it, I get a transparent effect. But I want it to be opaque. If it was a rectangular region, we could use the ROI as we did in the previous section. But flower is not a rectangular region. This is where bitwise operations, like AND, OR, NOT and XOR really come in handy. The associated functions are cv.bitwise_and(), cv.bitwise_or() and cv.bitwise_not(). You need to use cv.threshold function to segment the flower. Please refer to online documentation for more info. The result should resemble the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29d470c4-0685-4c86-919b-f57e5b057408",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower = cv.imread('images/flower.jfif')\n",
    "bee = cv.imread('images/native-bee.png')\n",
    "\n",
    "flower_gray = cv.cvtColor(flower, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create a binary mask of the flower\n",
    "_, mask = cv.threshold(flower_gray, 75, 255, cv.THRESH_BINARY)\n",
    "\n",
    "# Invert the mask\n",
    "mask_inv = cv.bitwise_not(mask)\n",
    "\n",
    "# Define the top-left corner of where the flower will be placed on the bee image\n",
    "top_left_x = 0\n",
    "top_left_y = 0\n",
    "\n",
    "flower_height, flower_width = flower.shape[:2]\n",
    "\n",
    "# Get ROI on the bee image where the flower will be placed\n",
    "roi = bee[top_left_y:top_left_y + flower_height, top_left_x:top_left_x + flower_width].copy()\n",
    "\n",
    "# Extract the flower region from the flower image using the mask\n",
    "flower_fg = cv.bitwise_and(flower, flower, mask=mask)\n",
    "\n",
    "# Extract the background region from the bee image using the inverted mask\n",
    "bee_bg = cv.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "# Combine the flower foreground and the bee background\n",
    "result_roi = cv.add(bee_bg, flower_fg)\n",
    "\n",
    "# Place the combined ROI back into the original bee image\n",
    "bee[top_left_y:top_left_y + flower_height, top_left_x:top_left_x + flower_width] = result_roi\n",
    "display_image(\"Combined Image\", result_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b95c10-7dc7-42b9-9edb-0c78c5237d1d",
   "metadata": {},
   "source": [
    "##### 3)Write a function that randomly crop the central region of an image. The method signature should be as shown in the following:\n",
    "- random_center_crop(image, min_crop_ratio, max_crop_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d6098e4-75af-4a61-ad01-344da0823302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_center_crop(image, min_crop_ratio, max_crop_ratio):\n",
    "    \"\"\"\n",
    "    Randomly crop the central region of an image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - min_crop_ratio: Minimum ratio for cropping (0.0 to 1.0).\n",
    "    - max_crop_ratio: Maximum ratio for cropping (0.0 to 1.0).\n",
    "\n",
    "    Returns:\n",
    "    - Cropped image (numpy array).\n",
    "    \"\"\"\n",
    "    if min_crop_ratio < 0.0 or min_crop_ratio > 1.0:\n",
    "        raise ValueError(\"min_crop_ratio must be between 0.0 and 1.0\")\n",
    "    elif max_crop_ratio < 0.0 or max_crop_ratio > 1.0:\n",
    "        raise ValueError(\"max_crop_ratio must be between 0.0 and 1.0\")\n",
    "    elif min_crop_ratio > max_crop_ratio:\n",
    "        raise ValueError(\"min_crop_ratio must not be greater than max_crop_ratio\")\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    min_crop_size = int(min(height, width) * min_crop_ratio)\n",
    "    max_crop_size = int(min(height, width) * max_crop_ratio)\n",
    "\n",
    "    # Randomly select crop size\n",
    "    crop_size = np.random.randint(min_crop_size, max_crop_size + 1)\n",
    "\n",
    "    # Calculate crop region\n",
    "    start_x = max(0, (width - crop_size) // 2)\n",
    "    start_y = max(0, (height - crop_size) // 2)\n",
    "    end_x = start_x + crop_size\n",
    "    end_y = start_y + crop_size\n",
    "\n",
    "    # Perform crop\n",
    "    cropped_image = image[start_y:end_y, start_x:end_x]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "img = random_center_crop(cv.imread(\"images\\lena.jfif\"), 0.1, 0.5)\n",
    "display_image(\"result\",img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f45cd96-4c9b-4fb9-85f6-ee3d991ecb60",
   "metadata": {},
   "source": [
    "##### 4)Aside from Gaussian noise, name another common type of noise. Write the code to demonstrate how the noise can be included in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "012c980c-771c-4183-8983-f8c1552b1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_and_pepper_noise(image, salt_prob, pepper_prob):\n",
    "    \"\"\"\n",
    "    Add salt and pepper noise to an image.\n",
    "    Parameters:\n",
    "    - Input image (numpy array).\n",
    "    - salt_prob (float): Probability of adding salt noise to a pixel (0 to 1).\n",
    "    - pepper_prob (float): Probability of adding pepper noise to a pixel (0 to 1).\n",
    "    \n",
    "    Returns:\n",
    "    Image (numpy array) with added salt and pepper noise.\n",
    "    \"\"\"\n",
    "    noisy_image = np.copy(image)\n",
    "    \n",
    "    # Salt noise\n",
    "    salt_mask = np.random.random(image.shape[:2]) < salt_prob\n",
    "    noisy_image[salt_mask] = 255\n",
    "    # Pepper noise\n",
    "    pepper_mask = np.random.random(image.shape[:2]) < pepper_prob\n",
    "    noisy_image[pepper_mask] = 0\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76bf5d51-4803-4b0e-a209-0afda0b118ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/dog.jfif\")\n",
    "noisy_image = add_salt_and_pepper_noise(img,0.05,0.1)\n",
    "display_images([img,noisy_image],(\"Original\",\"Noisy_Image\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4c72a-99a9-413b-b73f-6498f6a04475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
